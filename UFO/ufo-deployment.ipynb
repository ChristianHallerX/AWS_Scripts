{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UFO Model Deployment\n",
    "\n",
    "### Goal: Train and deploy model into SageMaker hosting.\n",
    "\n",
    "Steps:\n",
    "1. [Load dataset onto Notebook instance memory from S3](#Step-1:-Load-the-data-from-Amazon-S3)\n",
    "1. [Cleaning, transforming and preparing the dataset](#Step-2:-Cleaning,-transforming-and-preparing-the-dataset)\n",
    "1. [Training with Linear Learner](#Step-3:-Training-with-Linear-Learner)\n",
    "1. [Deploying into SageMaker hosting](#Step-4:-Deploying-the-model-into-SageMaker-hosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import io\n",
    "import sagemaker.amazon.common as smac\n",
    "\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading the data from Amazon S3\n",
    "Read from S3 into Pandas df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "bucket='ml_ufo_sightings'\n",
    "sub_folder = 'ufo_dataset'\n",
    "data_key = 'ufo_fullset.csv'\n",
    "data_location = 's3://{}/{}/{}'.format(bucket, sub_folder, data_key)\n",
    "\n",
    "df = pd.read_csv(data_location, low_memory=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Cleaning, transforming and preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values with the most common shape\n",
    "df['shape'] = df['shape'].fillna(df['shape'].value_counts().index[0])\n",
    "\n",
    "# timestamps/dates to 'date' data type\n",
    "df['reportedTimestamp'] = pd.to_datetime(df['reportedTimestamp'])\n",
    "df['eventDate'] = pd.to_datetime(df['eventDate'])\n",
    "\n",
    "# 'Shape' and 'weather' and 'researchoutcome' to 'category' data type.\n",
    "df['shape'] = df['shape'].astype('category')\n",
    "df['weather'] = df['weather'].astype('category')\n",
    "df['researchOutcome'] = df['researchOutcome'].astype('category')\n",
    "\n",
    "# 'physical evidence' and 'contact' to numerical\n",
    "df['physicalEvidence'] = df['physicalEvidence'].replace({'Y': 1, 'N': 0})\n",
    "df['contact'] = df['contact'].replace({'Y': 1, 'N': 0})\n",
    "\n",
    "# Remove uninformative variables\n",
    "df.drop(columns=['firstName', 'lastName', 'sighting', 'reportedTimestamp', 'eventDate', 'eventTime'], inplace=True)\n",
    "\n",
    "# one-hot 'weather' and 'shape' attributes\n",
    "df = pd.get_dummies(df, columns=['weather', 'shape'])\n",
    "\n",
    "#Target variable\n",
    "# Replace the 'researchOutcome' values with 0 = Unexplained, 1 = Explained, 2 = Probable\n",
    "df['researchOutcome'] = df['researchOutcome'].replace({'unexplained': 0, 'explained': 1, 'probable': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(df.head())\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Training with Linear Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random shuffle and split\n",
    "np.random.seed(0)\n",
    "rand_split = np.random.rand(len(df))\n",
    "train_list = rand_split < 0.8\n",
    "val_list = (rand_split >= 0.8) & (rand_split < 0.9)\n",
    "test_list = rand_split >= 0.9\n",
    "\n",
    "# train\n",
    "data_train = df[train_list]\n",
    "# validation\n",
    "data_val = df[val_list]\n",
    "# test\n",
    "data_test = df[test_list]\n",
    "\n",
    "# split train into x and y\n",
    "train_X = data_train.drop(columns='researchOutcome').values\n",
    "train_y = data_train['researchOutcome'].values\n",
    "# split val into x and y\n",
    "val_X = data_val.drop(columns='researchOutcome').values\n",
    "val_y = data_val['researchOutcome'].values\n",
    "# split test into x and y\n",
    "test_X = data_test.drop(columns='researchOutcome').values\n",
    "test_y = data_test['researchOutcome'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train: Create recordIO file pipe mode training and save on S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'ufo_sightings_train_recordIO_protobuf.data'\n",
    "\n",
    "f = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(f, train_X.astype('float32'), train_y.astype('float32'))\n",
    "f.seek(0)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object('implementation_operations_lab/linearlearner_train/{}'.format(train_file)).upload_fileobj(f)\n",
    "training_recordIO_protobuf_location = 's3://{}/implementation_operations_lab/linearlearner_train/{}'.format(bucket, train_file)\n",
    "print('The Pipe mode recordIO protobuf training data: {}'.format(training_recordIO_protobuf_location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation: Create recordIO file pipe mode training and save on S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_file = 'ufo_sightings_validatioin_recordIO_protobuf.data'\n",
    "\n",
    "f = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(f, val_X.astype('float32'), val_y.astype('float32'))\n",
    "f.seek(0)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object('implementation_operations_lab/linearlearner_validation/{}'.format(validation_file)).upload_fileobj(f)\n",
    "validate_recordIO_protobuf_location = 's3://{}/implementation_operations_lab/linearlearner_validation/{}'.format(bucket, validation_file)\n",
    "print('The Pipe mode recordIO protobuf validation data: {}'.format(validate_recordIO_protobuf_location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call Linear Learner ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "import sagemaker\n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name, 'linear-learner', \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training job name\n",
    "job_name = 'ufo-linear-learner-job-{}'.format(datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "print('Job name {}'.format(job_name))\n",
    "\n",
    "# Model artifact output path\n",
    "output_location = 's3://{}/implementation_operations_lab/linearlearner_output'.format(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters and train with fit fucnction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('The \"feature_dim\" hyperparameter is: {}.'.format(data_train.shape[1] - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "# Setup the LinearLeaner algorithm from the ECR container\n",
    "linear = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       train_instance_count=1, \n",
    "                                       train_instance_type='ml.c4.xlarge',\n",
    "                                       output_path=output_location,\n",
    "                                       sagemaker_session=sess,\n",
    "                                       input_mode='Pipe')\n",
    "# Setup the hyperparameters\n",
    "linear.set_hyperparameters(feature_dim=22,\n",
    "                            predictor_type='multiclass_classifier',\n",
    "                            num_classes=3,\n",
    "                            early_stopping_patience=3,\n",
    "                            epochs=15,\n",
    "                            l1=0.064774153906635,\n",
    "                            learning_rate=0.0932904024421902,\n",
    "                            loss='auto',\n",
    "                            mini_batch_size=744,\n",
    "                            normalize_data='true',\n",
    "                            normalize_label='auto',\n",
    "                            num_models='auto',\n",
    "                            optimizer='auto',\n",
    "                            unbias_data='auto',\n",
    "                            unbias_label='auto',\n",
    "                            use_bias='true',\n",
    "                            wd=0.000212481391205101\n",
    "                          )\n",
    "\n",
    "# Launch a training job. This method calls the CreateTrainingJob API call\n",
    "data_channels = {\n",
    "    'train': training_recordIO_protobuf_location,\n",
    "    'validation': validate_recordIO_protobuf_location\n",
    "}\n",
    "linear.fit(data_channels, job_name=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Artifact Path: {}/{}/output/model.tar.gz'.format(output_location, job_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Deploying the model into SageMaker hosting\n",
    "\n",
    "Deploy the artifact into SageMaker hosting onto a single m4 instance. This will list in the SageMaker console as \"Endpoint\".\n",
    "\n",
    "Next step after this is predicting the test data and evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_predictor = linear.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to draw a confusion matrix/heatmap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None, \n",
    "                          cmap=None):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "            plt.cm.Greens\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='Actual',\n",
    "           xlabel='Predicted')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offline Batch Prediction: Pass 'test_X' into prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_deserializer, csv_serializer\n",
    "\n",
    "multiclass_predictor.content_type = 'text/csv'\n",
    "multiclass_predictor.serializer = csv_serializer\n",
    "multiclass_predictor.deserializer = json_deserializer\n",
    "\n",
    "predictions = []\n",
    "results = multiclass_predictor.predict(test_X)\n",
    "predictions += [r['predicted_label'] for r in results['predictions']]\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call Confusion matrix y_test vs y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set_context(\"paper\", font_scale=1.4)\n",
    "\n",
    "y_test = test_y\n",
    "y_pred = predictions\n",
    "\n",
    "class_names = np.array(['Unexplained', 'Explained', 'Probable'])\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
    "                      title='Confusion matrix',\n",
    "                      cmap=plt.cm.Blues)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Accuracy, Precision, F1 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test = data_test['researchOutcome']\n",
    "y_pred = predictions\n",
    "scores = precision_recall_fscore_support(y_test, y_pred, average='macro', labels=np.unique(y_pred))\n",
    "print('Precision is: {}'.format(scores[0]))\n",
    "print('Recall is: {}'.format(scores[1]))\n",
    "print('F1 score is: {}'.format(scores[2]))\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy is: {}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
